{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Promemoria: questo üìò `.NET Interactive` deve essere eseguito da VS Code con [questi prerequisiti](../PREREQS.md).\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # Recipe II: üçΩÔ∏è First Dish\n",
    "## üßë‚Äçüç≥ Let's cook our üßÇüî• first basic dish\n",
    "\n",
    "This notebook has been designed as your \"classroom kitchen\" to get you started quickly with this Semantic Kernel ‚Äî the easy way to add LLM AI to your app. It's in three parts that is best described with technospeak so you get everything just right:\n",
    "\n",
    "1. **Setting up your OpenAI or Azure OpenAI Service key.** This lets you use this notebook like a playground of sorts. And you only have to enter your key once to get going ‚Äî it stores it locally into a file called \"settings.json\" on your disk. üôÄ Be sure to not let that file show up publicly anywhere like on your personal GitHub repo ‚Äî so please .gitignore it.\n",
    "\n",
    "2. **Getting a üî• kernel instantiated.** With your OpenAI or Azure OpenAI key you can then create a kernel to send instructions to. We've made it easy for you to use either OpenAI or Azure OpenAI. When using OpenAI, it will default to your using the `text-davinci-003` model; when you use Azure OpenAI there's an extra endpoint setting to consider ‚Äî and in addition you're asked explicitly for the model you would like to use.\n",
    "\n",
    "3. **Run a semantic üßÇ function.** Okay! You're ready to give your LLM AI a natural language prompt expressed as natural language. We call this kind of interaction with the model \"semantic\" because it lives in the world of the underlying meaning of the text you give to the model.  -->\n",
    "\n",
    "# Ricetta II: üçΩÔ∏è Primo piatto\n",
    "## üßë‚Äçüç≥ Cuciniamo il nostro üõ¢Ô∏èüî• primo piatto base\n",
    "\n",
    "<!-- This notebook has been designed as your \"classroom kitchen\" to get you started quickly with this Semantic Kernel ‚Äî the easy way to add LLM AI to your app. It's in three parts that is best described with technospeak so you get everything just right: -->\n",
    "\n",
    "Questo quaderno √® stato concepito per mostrare il modo pi√π semplice per aggiungere l'intelligenza artificiale LLM a una vostra applicazione. \n",
    "√à suddiviso in tre parti:\n",
    "\n",
    "1. **Impostazione della chiave OpenAI o Azure OpenAI Service.** In questo modo √® possibile utilizzare il notebook come una sorta di parco giochi. √à sufficiente inserire la chiave una sola volta per iniziare: viene memorizzata localmente in un file chiamato \"`settings.json`\" sul disco. Assicuratevi che questo file non venga visualizzato pubblicamente da nessuna parte, come ad esempio sul vostro repo personale di GitHub.\n",
    "\n",
    "2. **Ottenere un kernel üî• istanziato.** Con la chiave OpenAI o Azure OpenAI √® possibile creare un kernel a cui inviare le istruzioni.\n",
    "Quando si usa OpenAI, viene utilizzato per default il modello `text-davinci-003`; quando si usa Azure OpenAI c'√® un'ulteriore impostazione dell'endpoint da considerare e inoltre viene chiesto esplicitamente il modello che si desidera utilizzare.\n",
    "\n",
    "3. **Eseguire una semantic üõ¢Ô∏è function.** Ok! Siete pronti a fare una richiesta in linguaggio naturale all'intelligenza artificiale LLM."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1Ô∏è: Impostare la chiave OpenAI o Azure OpenAI Service\n",
    "\n",
    "### 1.1: Il sistema vi chieder√† di digitare la vostra chiave API segreta.\n",
    "\n",
    "The boolean variable below `useAzureOpenAI` should be set to `false` if you are using a regular OpenAI key, and `true` if you have an Azure OpenAI Service key. Whichever way you set the variable, a rectangular box will appear at the üëÜ top üëÜ of the notebook page ‚Äî asking you to enter the credentials.\\\n",
    "These credentials are stored locally on your own disk and don't go anywhere else. Once you hit the ‚ñ∂Ô∏è button to run the code, be sure to üëÜ look up to the top of this notebook page to enter your creds.\n",
    "\n",
    "La variabile booleana sottostante `useAzureOpenAI` deve essere impostata su `false` se si utilizza una normale chiave OpenAI e su `true` se si dispone di una chiave Azure OpenAI Service. Qualunque sia l'impostazione della variabile, nella üëÜ parte superiore üëÜ della pagina apparir√† un riquadro rettangolare che chieder√† di inserire le credenziali.\\\n",
    "Queste credenziali sono memorizzate **localmente** sul proprio disco e non vanno da nessuna parte.\n",
    "\n",
    "<!-- You will only see the ‚ñ∂Ô∏è (play) when you hover over the code block below, or you click on it to select it.  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: OK: Azure OpenAI endpoint configured [../config/settings.json]\n",
      "Settings: OK: deployment name configured [../config/settings.json]\n",
      "Settings: OK: API key configured [../config/settings.json]\n"
     ]
    }
   ],
   "source": [
    "#!import ../config/Settings.cs\n",
    "\n",
    "bool useAzureOpenAI = true;\n",
    "\n",
    "await Settings.AskAzureEndpoint(useAzureOpenAI);\n",
    "await Settings.AskModel(useAzureOpenAI);\n",
    "await Settings.AskApiKey(useAzureOpenAI);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- If you can see a confirmation line above that goes `Settings: OK: AI model configured ...` then proceed to step 2. Note that this is done only once. Your credentials are good to go. -->\n",
    "\n",
    "RICORDA: √® sufficiente eseguire questa operazione **una volta**. Il resto dei notebook utilizzer√† la chiave API memorizzata sul vostro computer in questo importante passaggio."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ### 1.2 In case you mistyped your API key information, follow these instructions -->\n",
    "### 1.2 Nel caso in cui si sia commesso un errore di immissione, seguire le seguenti istruzioni\n",
    "\n",
    "#### üü° **SALTA QUESTO STEP** se la chiave √® gi√† stata impostata con successo\n",
    "\n",
    "Premere il pulsante ‚ñ∂Ô∏è solo se si desidera ripristinare quanto inserito in precedenza. Prima di farlo, √® necessario \"decommentare\" due caratteri eliminando `//` all'inizio della riga 4.\n",
    "\n",
    "In altre parole, cambiare `// Settings.Reset();` in `Settings.Reset();`. In questo modo si \"decommenta\" quella riga di codice, in modo che diventi attiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings deleted. Run the notebook again to configure your AI backend.\r\n"
     ]
    }
   ],
   "source": [
    "#!import ../config/Settings.cs\n",
    "\n",
    "// Uncomment the line below to reset your settings and run step 1.1 again so it asks you for your API key\n",
    "// Settings.Reset();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2Ô∏è: Preparare un kernel üî• per cucinare il primo piatto\n",
    "\n",
    "Congratulazioni! Siete a un terzo del percorso! Premete ‚ñ∂Ô∏è per accedere alle credenziali memorizzate localmente, impostate nel primo passo. Questo passo carica il pacchetto Microsoft.SemanticKernel e prepara il resto del blocco note per far funzionare subito la funzione semantica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Microsoft.SemanticKernel, 0.9.61.1-preview</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget: Microsoft.SemanticKernel, 0.9.61.1-preview\"\n",
    "\n",
    "#!import ../config/Settings.cs\n",
    "\n",
    "using Microsoft.SemanticKernel;\n",
    "using Microsoft.SemanticKernel.KernelExtensions;\n",
    "using System.IO;\n",
    "using Microsoft.SemanticKernel.Configuration;\n",
    "using Microsoft.SemanticKernel.SemanticFunctions;\n",
    "\n",
    "IKernel kernel = Microsoft.SemanticKernel.Kernel.Builder.Build();\n",
    "\n",
    "// Grab the locally stored credentials from the settings.json file. \n",
    "// Name the service as \"davinci\" ‚Äî assuming that you're using one of the davinci completion models. \n",
    "var (useAzureOpenAI, model, azureEndpoint, apiKey, orgId) = Settings.LoadFromFile();\n",
    "\n",
    "if (useAzureOpenAI)\n",
    "    kernel.Config.AddAzureOpenAITextCompletion(\"davinci\", model, azureEndpoint, apiKey);\n",
    "else\n",
    "    kernel.Config.AddOpenAITextCompletion(\"davinci\", model, apiKey, orgId);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se si vede una linea di conferma in alto che inizia con `Installed Packages ... ‚Ä¢ Microsoft.SemanticKernel, ...` procedere al punto 3.\n",
    "\n",
    "<!-- üò± **Get an error message?** The most common error is accidentally resetting your credentials file, or setting it up with the wrong information. Look at the 'settings.json' file in your config directory to make sure your settings make sense. And if you're still stuck, go to https://aka.ms/sk/discord where we have realtime support. -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3Ô∏è: Eseguire una funzione semantica üõ¢Ô∏è in Semantic Kernel per üî•cuocere \n",
    "\n",
    "<!-- Before you set off to write a semantic function, review our documentation on semantic functions at our [learning hub](https://learn.microsoft.com/en-us/semantic-kernel/howto/semanticfunctions). You'll want to feel comfortable with two ideas: -->\n",
    "\n",
    "Bastano questi due concetti:\n",
    "\n",
    "* Creare un prompt **parametrizzato** con una sola variabile - `$input` √® la variabile di input predefinita. \\[[Approfondimento](https://learn.microsoft.com/semantic-kernel/howto/semanticfunctions#writing-a-more-powerful-templated-prompt)\\]\n",
    "\n",
    "* Configurare il prompt con alcune **impostazioni standard** - `MaxTokens`, `Temperature`, `TopP`. \\[[Approfondimento](https://learn.microsoft.com/en-us/semantic-kernel/howto/configuringfunctions)\\]\n",
    "\n",
    "Mancano solo tre passi all'esecuzione di una funzione semantica. Preparatevi!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.1: Definire un prompt parametrizzato che accetta un singolo input\n",
    "\n",
    "Il codice seguente √® quello che chiamiamo \"funzione semantica\", che √® quasi equivalente alla parola \"prompt\". \n",
    "Si sentir√† parlare di questi termini in modo intercambiabile. Inoltre, sentirete la frase \"skill semantica\" e vi chiederete: \"√à la stessa cosa di una funzione semantica?\". No, ma √® sono collegato. Non preoccupatevi e continuate ad andare avanti!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A string has been set to be used as a semantic function.\r\n"
     ]
    }
   ],
   "source": [
    "string mySemanticFunctionInline = \"\"\"\n",
    "{{$input}}\n",
    "\n",
    "Summarize the content above in less than 140 characters.\n",
    "\"\"\";\n",
    "\n",
    "Console.WriteLine(\"A string has been set to be used as a semantic function.\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quindi la funzione semantica che stiamo per definire prende un testo `$input` e lo riassume in meno di 140 caratteri."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.2: Configurare il prompt per renderlo pi√π non deterministico (creativo) o deterministico (diretto)\n",
    "\n",
    "#### üîµ FAST TRACK Most people will just run the code below without much thought to tuning it, to start\n",
    "\n",
    "L'impostazione `MaxTokens` determina il numero massimo di tokens da generare nel completamento. √à il parametro pi√π importante [setting](https://learn.microsoft.com/en-us/semantic-kernel/howto/configuringfunctions) da conoscere, perch√© ha un impatto su quanto spendete per ogni richiesta.\n",
    "\n",
    "Inoltre, √® possibile modellare in modo sottile l'uscita della risposta con gli altri due parametri. Per rendere la risposta pi√π o meno \"creativa\", si pu√≤ regolare l'impostazione `Temperatura' tra 0 e 1`. √à inoltre possibile impostare il parametro `TopP` tra 0 (vocabolario pi√π piccolo) e 1 (vocabolario pi√π grande) per ottenere un risultato diverso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A semantic function has been registered.\r\n"
     ]
    }
   ],
   "source": [
    "using Microsoft.SemanticKernel.KernelExtensions;\n",
    "using Microsoft.SemanticKernel.SemanticFunctions;\n",
    "\n",
    "var promptConfig = new PromptTemplateConfig\n",
    "{\n",
    "    Completion =\n",
    "    {\n",
    "        MaxTokens = 1000, Temperature = 0.2, TopP = 0.5,\n",
    "    }\n",
    "};\n",
    "\n",
    "var promptTemplate = new PromptTemplate(\n",
    "    mySemanticFunctionInline, promptConfig, kernel\n",
    ");\n",
    "\n",
    "var functionConfig = new SemanticFunctionConfig(promptConfig, promptTemplate);\n",
    "\n",
    "// \"MySkill\" is the name of the skill\n",
    "// \"Summary\" is the name of the semantic function\n",
    "var summaryFunction = kernel.RegisterSemanticFunction(\"MySkill\", \"Summary\", functionConfig);\n",
    "\n",
    "Console.WriteLine(\"A semantic function has been registered.\");\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.3: Set your input to the templated prompt and have the kernel üî• process it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2023 will be the most exciting year for AI yet, with generative AI tools like GPT-3 and DALL-E 2 creating new works from text inputs.\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "var input = \"\"\"\n",
    "I think with some confidence I can say that 2023 is going to be the most exciting year that \n",
    "the AI community has ever had,‚Äù writes Kevin Scott, chief technology officer at Microsoft, \n",
    "in a Q&A on the company‚Äôs AI blog. He acknowledges that he also thought 2022 was the most \n",
    "exciting year for AI, but he believes that the pace of innovation is only increasing. \n",
    "This is particularly true with generative AI, which doesn‚Äôt simply analyze large data sets \n",
    "but is a tool people can use to create entirely new works. We can already see its promise \n",
    "in systems like GPT-3, which can do anything from helping copyedit and summarize text to \n",
    "providing inspiration, and DALL-E 2, which can create useful and arresting works of art \n",
    "based on text inputs. Here are some of Scott‚Äôs predictions about how AI will change the \n",
    "way we work and play.\n",
    "\"\"\";\n",
    "// Text source: https://www.microsoft.com/en-us/worklab/kevin-scott-on-5-ways-generative-ai-will-transform-work-in-2023\n",
    "\n",
    "var summary = await kernel.RunAsync(input, summaryFunction);\n",
    "\n",
    "Console.WriteLine(summary);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéâ Hai appena creato la tua prima funzione semantica usando Semantic Kernel. Congratulazioni üî•!\n",
    "\n",
    "<!-- > ‚úÖ Be sure to use `text-davinci-003` instead of the more trendy `gpt-3.5-turbo` when you run the above. -->\n",
    "\n",
    "> ü§î **Ottieni il seguente `\"Error: Throttling: Too many requests ...\"` messaggio?** I servizi OpenAI risultano essere estremamente popolari in questi giorni. Se si utilizza la chiave per un account gratuito, questo messaggio apparir√† spesso.\n",
    "\n",
    "<!-- > üò± **Get a different error message?** If you can't see a summarization of the text above, then go to https://aka.ms/sk/discord where we have realtime support available to troubleshoot your problem. -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚è≠Ô∏è I prossimi passi\n",
    "\n",
    "Esempi pi√π avanzati nei notebook disponibili nel repo GitHub all'indirizzo [https://aka.ms/sk/repo](https://aka.ms/sk/repo).\n",
    "\n",
    "[Vediamo le üõ¢Ô∏è skills!](../e3-skills-rack/notebook.ipynb)\n",
    "\n",
    "<!-- Or stay a longer while and change the prompt above to your liking; and also the `$input` and other parameters to your liking. Please keep in mind that each API call to OpenAI or Azure OpenAI Services will use up tokens. -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "polyglot-notebook"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "languageName": "csharp",
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
